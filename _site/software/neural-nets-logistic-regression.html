<!DOCTYPE html>
<html>
<head>
  <title>Logistic Regression with a Neural Network mindset using NumPy and Python – Gogul Ilango </title>

  <link href="https://fonts.googleapis.com/css?family=Poppins:200,400|Roboto:300" rel="stylesheet">
  <link rel="shortcut icon" type="image/png" href="/images/favicon_gi.png"/>

  <meta name="viewport" content="width=device-width, initial-scale=.5, maximum-scale=12.0, minimum-scale=.25, user-scalable=yes"/>

      <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    <meta property="og:title" content="Logistic Regression with a Neural Network mindset using NumPy and Python" />
    <meta name="description" content="Build a binary classifier logistic regression model with a neural network mindset using numpy and python." />
    <meta property="og:description" content="Build a binary classifier logistic regression model with a neural network mindset using numpy and python." />
    <meta property="twitter:title" content="Logistic Regression with a Neural Network mindset using NumPy and Python" />

    <meta property="og:image" content="https://drive.google.com/uc?id=1XHhFGbejMAuNJlY5PUMtodBjaHhZ9rQd"/>
    <meta property="og:image:width" content="180" />
    <meta property="og:image:height" content="110" />

    <meta name="twitter:title" content="Logistic Regression with a Neural Network mindset using NumPy and Python">
    <meta name="twitter:description" content="Build a binary classifier logistic regression model with a neural network mindset using numpy and python.">
    <meta name="twitter:image" content="https://drive.google.com/uc?id=1XHhFGbejMAuNJlY5PUMtodBjaHhZ9rQd">
  <!-- Begin Jekyll SEO tag v2.2.2 -->
<title>Logistic Regression with a Neural Network mindset using NumPy and Python | Gogul Ilango</title>
<meta property="og:title" content="Logistic Regression with a Neural Network mindset using NumPy and Python" />
<meta name="author" content="Gogul Ilango" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Build a binary classifier logistic regression model with a neural network mindset using numpy and python." />
<meta property="og:description" content="Build a binary classifier logistic regression model with a neural network mindset using numpy and python." />
<link rel="canonical" href="http://localhost:4000/software/neural-nets-logistic-regression" />
<meta property="og:url" content="http://localhost:4000/software/neural-nets-logistic-regression" />
<meta property="og:site_name" content="Gogul Ilango" />
<meta property="og:image" content="https://drive.google.com/uc?id=1XHhFGbejMAuNJlY5PUMtodBjaHhZ9rQd" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-12-23T00:00:00+05:30" />
<script type="application/ld+json">
{"@context":"http://schema.org","@type":"BlogPosting","headline":"Logistic Regression with a Neural Network mindset using NumPy and Python","author":{"@type":"Person","name":"Gogul Ilango"},"image":"https://drive.google.com/uc?id=1XHhFGbejMAuNJlY5PUMtodBjaHhZ9rQd","datePublished":"2017-12-23T00:00:00+05:30","dateModified":"2017-12-23T00:00:00+05:30","description":"Build a binary classifier logistic regression model with a neural network mindset using numpy and python.","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/software/neural-nets-logistic-regression"},"url":"http://localhost:4000/software/neural-nets-logistic-regression"}</script>
<!-- End Jekyll SEO tag -->


  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-1792372637327333",
            enable_page_level_ads: true
       });
  </script>
  
  <!--[if lt IE 9]><script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <!--[if lte IE 8]><script type="text/javascript" src="excanvas.js"></script><![endif]-->
    <meta name="theme-color" content="#252525" />
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Gogul Ilango - This blog on Deep Learning, VLSI Design and STA is written by Gogul Ilango. Master VLSI Design, Physical Design, Static Timing Analysis, Deep Learning through my articles, tutorials and resources." href="/feed.xml" />
  </head>

  <body>
    <div class="outer-wrapping">
      <div class="inner-container">
          <div class="header-left">
            <a class='logo' href="https://gogul09.github.io/"><img src="/images/icons/logo.png"/></a>
          </div>
          <div class="topnav header-right" id="top_navigator">
            <a title="home" id = "nav_home" href="/"></a>
            <a title="creations" id = "nav_creations" href="/creations"></a>
            <a title="music" id = "nav_music" href="/music"></a>
            <a title="about" id = "nav_about" href="/about"></a>
            <a href = "javascript:void(0);" style="font-size:14px;" class="icon" onclick="top_navigation()">&#9776;</a>
          </div>
      </div>
    </div>

    <div id="main" role="main">
      <div class="post-heading post-heading-wrapper post-image">
	<div class="grad-post">
		<h1>Logistic Regression with a Neural Network mindset using NumPy and Python</h1>
		<div class="post-subheading">
			<p>Deep Learning | 23 December 2017</p>
			<p><a href="#show_comments" id="comment-count" class="disqus-comment-count" data-disqus-url="https://gogul09.github.io/software/neural-nets-logistic-regression"></a></p>
		</div>
	</div>
</div>

<div class="containing">
	<div class="wrapping">

		<div class="share-box">
	<button class="top-share-fab" id="top-share-fab" onclick="showShareBox(this.id)"></button>
	<div id="top-share-box" class="top-share-box">
		<h5>Share</h5>
		<ul>
			<li class="whatsapp-white"><a href="whatsapp://send?text=http://localhost:4000/software/neural-nets-logistic-regression" data-action="share/whatsapp/share">WhatsApp</a></li>
			<li class="facebook-white"><a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/software/neural-nets-logistic-regression" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" >Facebook</a></li>
			<li class="twitter-white"><a href="https://twitter.com/intent/tweet?text=Logistic Regression with a Neural Network mindset using NumPy and Python&url=http://localhost:4000/software/neural-nets-logistic-regression" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;">Twitter</a></li>
			<li class="linkedin-white"><a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/software/neural-nets-logistic-regression&title=Logistic Regression with a Neural Network mindset using NumPy and Python&summary=Build a binary classifier logistic regression model with a neural network mindset using numpy and python.&source=webjeda" onclick="window.open(this.href, 'mywin', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" >LinkedIn</a></li>
		</ul>
	</div>
</div>

		<div class="post-cover">

			<article class="post">
				<div class="entry">
					<div class="git-showcase">
  <div>
    <a class="github-button" href="https://github.com/Gogul09" data-show-count="true" aria-label="Follow @Gogul09 on GitHub">Follow @Gogul09</a>
  </div>

  <div>
    <a class="github-button" href="https://github.com/Gogul09/deep-learning-fundamentals/fork" data-icon="octicon-repo-forked" data-show-count="true" aria-label="Fork Gogul09/deep-learning-fundamentals on GitHub">Fork</a>
  </div>

  <div>
    <a class="github-button" href="https://github.com/Gogul09/deep-learning-fundamentals" data-icon="octicon-star" data-show-count="true" aria-label="Star Gogul09/deep-learning-fundamentals on GitHub">Star</a>
  </div>  
</div>

<div class="sidebar_tracker" id="sidebar_tracker">
  <button onclick="closeSidebar('sidebar_tracker_content')">X</button>
  <p onclick="showSidebar('sidebar_tracker_content')">Contents</p>
  <ul id="sidebar_tracker_content">
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_1" href="#image-as-a-vector">Image as a vector</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_2" href="#dataset">Dataset</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_3" href="#logistic-regression-pipeline">Logisitic Regression pipeline</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_4" href="#logistic-regression-concept">Logistic Regression concept</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_5" href="#vectorization">Vectorization</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_6" href="#gradient-descent">Gradient Descent</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_7" href="#mathematical-equations">Mathematical equations</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_8" href="#math-to-code">Math to Code</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_9" href="#fitting-it-all-together">Fitting it all together</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_10" href="#training-the-model">Training the model</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_11" href="#testing-the-trained-model">Testing the trained model (optional)</a></li>
    <li><a class="sidebar_links" onclick="handleSideBarLinks(this.id)" id="link_12" href="#resources">Resources</a></li>
  </ul>
</div>

<p>Before understanding the math behind a Deep Neural Network and implementing it in code, it is better to get a mindset of how Logistic Regression could be modelled as a simple Neural Network that actually learns from data.</p>

<div class="code-head">Objectives</div>

<div class="highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6</pre></td><td class="code"><pre>After reading this post, we will understand

* How to convert an image into a vector?
* How to preprocess an existing image dataset to do Deep Learning?
* How to represent images and labels as numpy arrays?
* How to use just one for-loop to train a logistic regression model?
</pre></td></tr></tbody></table>
</div>
</div>

<p>A look at what we will be building at the end of this tutorial is shown below. A binary classifier that will classify an image as either <span class="coding">airplane</span> or <span class="coding">bike</span>.</p>

<figure>
  <img src="/images/software/logistic-regression/out.gif" class="typical-image" />
  <figcaption>Figure 1. Binary Classification using Logistic Regression Neural Network model</figcaption>
</figure>

<h3 id="image-as-a-vector">Image as a vector</h3>

<p>The input to the logistic regression model is an image. An image is a three-dimensional matrix that holds pixel intensity values of Red, Green and Blue channels. In Deep Learning, what we do first is that we convert this image (3d-matrix) to a 1d-matrix (also called as a vector).</p>

<p>For example, if our image is of dimension [640, 480, 3] where 640 is the width, 480 is the height and 3 is the number of channels, then the flattened version of the image or 1-d representation of the image will be [1, 921600].</p>

<p>Notice that in the above vector dimension, we represent the image as a row vector having 921600 columns.</p>

<p>To better understand this, look at the image below.</p>

<figure>
  <img src="/images/software/logistic-regression/image-to-vector.jpg" class="typical-image" />
  <figcaption>Figure 2. Image (3-d) to Vector (1-d)</figcaption>
</figure>

<h3 id="dataset">Dataset</h3>
<p>We will use the <a href="http://www.vision.caltech.edu/Image_Datasets/Caltech101/" target="_blank">CALTECH-101</a> dataset which has images belonging to 101 categories such as airplane, bike, elephant etc. As we are dealing with a binary classification problem, we will specifically use images from two categories <span class="coding">airplane</span> and <span class="coding">bike</span>.</p>

<p>Download this dataset and make sure you follow the below folder structure.</p>

<div class="code-head">Folder Structure<span>rule</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25</pre></td><td class="code"><pre><span class="o">|--</span><span class="n">logistic</span><span class="o">-</span><span class="n">regression</span>
<span class="o">|--|--</span><span class="n">dataset</span>
<span class="o">|--|--|--</span><span class="n">train</span>
<span class="o">|--|--|--|--</span><span class="n">airplane</span>
<span class="o">|--|--|--|--|--</span><span class="n">image_1</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">|--|--|--|--|--</span><span class="n">image_2</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">|--|--|--|--|--....</span>
<span class="o">|--|--|--|--|--</span><span class="n">image_750</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">|--|--|--|--</span><span class="n">bike</span>
<span class="o">|--|--|--|--|--</span><span class="n">image_1</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">|--|--|--|--|--</span><span class="n">image_2</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">|--|--|--|--|--....</span>
<span class="o">|--|--|--|--|--</span><span class="n">image_750</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">|--|--|--</span><span class="n">test</span>
<span class="o">|--|--|--|--</span><span class="n">airplane</span>
<span class="o">|--|--|--|--|--</span><span class="n">image_1</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">|--|--|--|--|--</span><span class="n">image_2</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">|--|--|--|--|--....</span>
<span class="o">|--|--|--|--|--</span><span class="n">image_50</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">|--|--|--|--</span><span class="n">bike</span>
<span class="o">|--|--|--|--|--</span><span class="n">image_1</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">|--|--|--|--|--</span><span class="n">image_2</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">|--|--|--|--|--....</span>
<span class="o">|--|--|--|--|--</span><span class="n">image_50</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">|--|--</span><span class="n">train</span><span class="o">.</span><span class="n">py</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>Inside the train folder, you need to create two sub-folders namely <span class="coding">airplane</span> and <span class="coding">bike</span>. You have to manually copy 750 images from <span class="coding">airplane</span> folder in “CALTECH-101” dataset to our <span class="coding">airplane</span> folder. Similarly, you have to manually copy 750 images from <span class="coding">motorbikes</span> folder in “CALTECH-101” dataset to our <span class="coding">bike</span> folder.</p>

<p>Inside the test folder, you have to do the same process, but now, you will be having 50 images in <span class="coding">airplane</span> and 50 images in <span class="coding">bike</span>.</p>

<p>Before starting anything, make sure you have the following number of images in each folder.</p>
<ul>
  <li>dataset -&gt; train -&gt; airplane -&gt; 750 images</li>
  <li>dataset -&gt; train -&gt; bike     -&gt; 750 images</li>
  <li>dataset -&gt; test  -&gt; airplane -&gt; 50  images</li>
  <li>dataset -&gt; test  -&gt; bike     -&gt; 50  images</li>
</ul>

<h4 id="prepare-the-dataset">Prepare the dataset</h4>

<p>Let’s fix the input image size with dimensions \([64, 64, 3]\), meaning \(64\) is the width and height with \(3\) channels. The flattened vector will then have dimension \([1, 12288]\). We will also need to know the total number of training images that we are going to use so that we can build an empty numpy array with that dimension and then fill it up after flattening every image. In our case, total number of train images <span class="coding">num_train_images</span> = \(1500\) and total number of test images <span class="coding">num_test_images</span> = \(100\).</p>

<p>We need to define four numpy arrays filled with zeros.</p>
<ul>
  <li>Array of dimension \([12288, 1500]\) to hold our train images.</li>
  <li>Array of dimension \([12288, 100]\) to hold our test images.</li>
  <li>Array of dimension \([1, 1500]\) to hold our train labels.</li>
  <li>Array of dimension \([1, 100]\) to hold our test labels.</li>
</ul>

<p>For each image in the dataset:</p>
<ul>
  <li>Convert the image into a matrix of fixed size using <span class="coding">load_img()</span> in Keras - \([64, 64, 3]\).</li>
  <li>Convert the image into a row vector using <span class="coding">flatten()</span> in NumPy - \([12288,]\)</li>
  <li>Expand the dimensions of the above vector using <span class="coding">np.expand_dims()</span> in NumPy - \([1, 12288]\)</li>
  <li>Concatenate this vector to a numpy array <span class="coding">train_x</span> of dimension \([12288, 1500]\).</li>
  <li>Concatenate this vector’s label to a numpy array  <span class="coding">train_y</span> of dimension \([1, 1500]\).</li>
</ul>

<p>We need to perform the above procedure for test data to get <span class="coding">test_x</span> and <span class="coding">test_y</span>.</p>

<p>We then standardize <span class="coding">train_x</span> and <span class="coding">test_x</span> by dividing each pixel intensity value by 255. This is because normalizing the image matrix makes our learning algorithm better.</p>

<p>Also, we will assign “0” as the label to <span class="coding">airplane</span> and “1” as the label to <span class="coding">bike</span>. This is very important as computers work only with numbers.</p>

<p>Finally, we can save all our four numpy arrays locally using <span class="coding">h5py</span> library.</p>

<p>Below is the code snippet to do all the above steps before building our logistic regression neural network model.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89</pre></td><td class="code"><pre><span class="c">#-------------------</span>
<span class="c"># organize imports</span>
<span class="c">#-------------------</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="kn">import</span> <span class="n">image</span>

<span class="c">#------------------------</span>
<span class="c"># dataset pre-processing</span>
<span class="c">#------------------------</span>
<span class="n">train_path</span>   <span class="o">=</span> <span class="s">"G:</span><span class="se">\\</span><span class="s">workspace</span><span class="se">\\</span><span class="s">machine-intelligence</span><span class="se">\\</span><span class="s">deep-learning</span><span class="se">\\</span><span class="s">logistic-regression</span><span class="se">\\</span><span class="s">dataset</span><span class="se">\\</span><span class="s">train"</span>
<span class="n">test_path</span>    <span class="o">=</span> <span class="s">"G:</span><span class="se">\\</span><span class="s">workspace</span><span class="se">\\</span><span class="s">machine-intelligence</span><span class="se">\\</span><span class="s">deep-learning</span><span class="se">\\</span><span class="s">logistic-regression</span><span class="se">\\</span><span class="s">dataset</span><span class="se">\\</span><span class="s">test"</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">train_path</span><span class="p">)</span>
<span class="n">test_labels</span>  <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">test_path</span><span class="p">)</span> 

<span class="c"># tunable parameters</span>
<span class="n">image_size</span>       <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">num_train_images</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">num_test_images</span>  <span class="o">=</span> <span class="mi">100</span>
<span class="n">num_channels</span>     <span class="o">=</span> <span class="mi">3</span>

<span class="c"># train_x dimension = {(64*64*3), 1500}</span>
<span class="c"># train_y dimension = {1, 1500}</span>
<span class="c"># test_x dimension  = {(64*64*3), 100}</span>
<span class="c"># test_y dimension  = {1, 100}</span>
<span class="n">train_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(((</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">num_channels</span><span class="p">),</span> <span class="n">num_train_images</span><span class="p">))</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_train_images</span><span class="p">))</span>
<span class="n">test_x</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(((</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">num_channels</span><span class="p">),</span> <span class="n">num_test_images</span><span class="p">))</span>
<span class="n">test_y</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_test_images</span><span class="p">))</span>

<span class="c">#----------------</span>
<span class="c"># TRAIN dataset</span>
<span class="c">#----------------</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">num_label</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_labels</span><span class="p">):</span>
	<span class="n">cur_path</span> <span class="o">=</span> <span class="n">train_path</span> <span class="o">+</span> <span class="s">"</span><span class="se">\\</span><span class="s">"</span> <span class="o">+</span> <span class="n">label</span>
	<span class="k">for</span> <span class="n">image_path</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">cur_path</span> <span class="o">+</span> <span class="s">"/*.jpg"</span><span class="p">):</span>
		<span class="n">img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="n">image_size</span><span class="p">)</span>
		<span class="n">x</span>   <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
		<span class="n">x</span>   <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
		<span class="n">x</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
		<span class="n">train_x</span><span class="p">[:,</span><span class="n">count</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
		<span class="n">train_y</span><span class="p">[:,</span><span class="n">count</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_label</span>
		<span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
	<span class="n">num_label</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c">#--------------</span>
<span class="c"># TEST dataset</span>
<span class="c">#--------------</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="n">num_label</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_labels</span><span class="p">):</span>
	<span class="n">cur_path</span> <span class="o">=</span> <span class="n">test_path</span> <span class="o">+</span> <span class="s">"</span><span class="se">\\</span><span class="s">"</span> <span class="o">+</span> <span class="n">label</span>
	<span class="k">for</span> <span class="n">image_path</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">cur_path</span> <span class="o">+</span> <span class="s">"/*.jpg"</span><span class="p">):</span>
		<span class="n">img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="n">image_size</span><span class="p">)</span>
		<span class="n">x</span>   <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
		<span class="n">x</span>   <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
		<span class="n">x</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
		<span class="n">test_x</span><span class="p">[:,</span><span class="n">count</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>
		<span class="n">test_y</span><span class="p">[:,</span><span class="n">count</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_label</span>
		<span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
	<span class="n">num_label</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c">#------------------</span>
<span class="c"># standardization</span>
<span class="c">#------------------</span>
<span class="n">train_x</span> <span class="o">=</span> <span class="n">train_x</span><span class="o">/</span><span class="mf">255.</span>
<span class="n">test_x</span>  <span class="o">=</span> <span class="n">test_x</span><span class="o">/</span><span class="mf">255.</span>

<span class="k">print</span> <span class="p">(</span><span class="s">"train_labels : "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_labels</span><span class="p">))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"train_x shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"train_y shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"test_x shape : "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">test_x</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"test_y shape : "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">test_y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

<span class="c">#-----------------</span>
<span class="c"># save using h5py</span>
<span class="c">#-----------------</span>
<span class="n">h5_train</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="s">"train_x.h5"</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span>
<span class="n">h5_train</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="s">"data_train"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_x</span><span class="p">))</span>
<span class="n">h5_train</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="n">h5_test</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="s">"test_x.h5"</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span>
<span class="n">h5_test</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="s">"data_test"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_x</span><span class="p">))</span>
<span class="n">h5_test</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></td></tr></tbody></table>
</div>
</div>

<div class="code-output highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5</pre></td><td class="code"><pre>train_labels : ['airplane', 'bike']
train_x shape: (12288, 1500)
train_y shape: (1, 1500)
test_x shape : (12288, 100)
test_y shape : (1, 100)
</pre></td></tr></tbody></table>
</div>
</div>

<h3 id="logistic-regression-pipeline">Logistic Regression pipeline</h3>

<figure>
  <img src="/images/software/logistic-regression/logistic-regression-neural-network.jpg" class="typical-image" />
  <figcaption>Figure 3. Logistic Regression - A Simple Neural Network</figcaption>
</figure>

<p>By looking at the above figure, the problem that we are going to solve is this -</p>

<blockquote>
  <p>Given an input image, our model must be able to figure out the label by telling whether it is an <span class="coding">airplane</span> or a <span class="coding">bike</span>.</p>
</blockquote>

<h4 id="a-simple-neuron">A simple neuron</h4>

<p>An artificial neuron (shown as purple circle in Figure 3) is a biologically inspired representation of a neuron inside human brain. Similar to a neuron in human brain, an artificial neuron accepts inputs from some other neurons and fires a value to the next set of artificial neurons. Inside a single neuron, two computations are performed.</p>
<ol>
  <li>Weighted sum</li>
  <li>Activation</li>
</ol>

<h4 id="weighted-sum">Weighted sum</h4>
<p>Every input value \(x_{(i)}\) to an artificial neuron has a weight \(w_{(i)}\) associated with it which tells about the relative importance of that input with other inputs. Each weight \(w_{(i)}\) is multiplied with its corresponding input \(x_{(i)}\) and gets summed up to produce a single value \(z\).</p>

<h4 id="activation">Activation</h4>
<p>After computing the weighted sum \(z\), an activation function \(a = g(z)\) is applied to this weighted sum \(z\). Activation function is a simple mathematical transformation of an input value to an output value by introducing a non-linearity. This is necessary because real-world inputs are non-linear and we need our neural network to learn this non-linearity somehow.</p>

<h3 id="logistic-regression-concept">Logistic Regression concept</h3>
<ol>
  <li>Initialize the weights <span class="coding">w</span> and biases <span class="coding">b</span> to random values (say 0 or using random distribution).</li>
  <li>Foreach training sample in the dataset -
    <ul>
      <li>Calculate the output value \(a^{(i)}\) for an input sample \(x^{(i)}\).
        <ul>
          <li>First: find out the weighted sum \(z^{(i)}\).</li>
          <li>Second: compute the activation value \(a^{(i)}\) = \(y’^{(i)}\) = \(g(z^{(i)})\) for the weighted sum \(z^{(i)}\).</li>
        </ul>
      </li>
      <li>As we know the true label for this input training sample \(y^{(i)}\), we use that to find the loss \(L(a^{(i)},y^{(i)})\).</li>
    </ul>
  </li>
  <li>Calculate the cost function \(J\) which is the sum of all losses divided by the number of training examples \(m\) i.e., \(\frac{1}{m}\sum_{i=1}^m L(a^{(i)},y^{(i)})\).</li>
  <li>To minimize the cost function, compute the gradients for parameters \(\frac{dJ}{dw}\) and \(\frac{dJ}{db}\) using chain rule of calculus.</li>
  <li>Use gradient descent to update the parameters <span class="coding">w</span> and <span class="coding">b</span>.</li>
  <li>Perform the above procedure till the cost function becomes minimum.</li>
</ol>

<h3 id="vectorization">Vectorization</h3>
<p>One interesting thing in the above algorithm is that we will not be using the for loop (2nd point) in code; rather we will use vectorization offered by numpy to speed up computations in an efficient way.</p>

<p>After successfully pre-processing the dataset, please look at the below image to visually understand how the dimensions of our numpy arrays look like.</p>

<figure>
  <img src="/images/software/logistic-regression/dimensions.jpg" class="typical-image" />
  <figcaption>Figure 4. Dimensions of weights, train image matrix, biases and labels.</figcaption>
</figure>

<p>As you can see, the weights array has a dimension of shape \([1, 12288]\) and biases array has a dimension of shape \([1, 1500]\). But you will see that we will be initializing bias as a single value. A concept called <span class="coding">broadcasting</span> automatically applies the single <span class="coding">b</span> value to the matrix of shape \([1, 1500]\).</p>

<h3 id="gradient-descent">Gradient Descent</h3>
<figure>
  <img src="/images/software/logistic-regression/computation-graph-1.jpg" class="typical-image" />
  <figcaption>Figure 5. Computing derivatives of parameters "w" and "b" with respect to loss function "L" on one training example.</figcaption>
</figure>

<p>The above figure shows us how to visualize forward propagation and backpropagation as a computation graph for one training example.</p>
<ul>
  <li>Forward propagation (for a single training example)
    <ul>
      <li>Calculate the weighted sum \(z = w_1x_1 + w_2x_2 + b\).</li>
      <li>Calculate the activation \(a = \sigma(z)\).</li>
      <li>Compute the loss \(L(a,y) = -ylog(a)+(1-y)log(1-a)\).</li>
    </ul>
  </li>
  <li>Backpropagation (for a single training example)
    <ul>
      <li>Compute the derivatives of parameters \(\frac{dL}{dw1}\), \(\frac{dL}{dw2}\) and \(\frac{dL}{db}\) using \(\frac{dL}{da}\) and \(\frac{dL}{dz}\).</li>
      <li>Use update rule to update the parameters.
        <ul>
          <li>\(w1 = w1 -\alpha \frac{dL}{dw1}\)</li>
          <li>\(w2 = w2 -\alpha \frac{dL}{dw2}\)</li>
          <li>\(b = b -\alpha \frac{dL}{db}\)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>In code, we will be denoting \(\frac{dL}{dw1}\) as <span class="coding">dw1</span>, \(\frac{dL}{dw2}\) as <span class="coding">dw2</span>, \(\frac{dL}{db}\) as <span class="coding">db</span>, \(\frac{dL}{da}\) as <span class="coding">da</span> and \(\frac{dL}{dz}\) as <span class="coding">dz</span>.</p>

<p>But in our problem we don’t just have 1 training example, rather \(m\) training examples. This is where cost function \(J\) comes into picture. So, we calculate losses for all the training examples, sum it up and divide by the number of training examples \(m\).</p>

<h3 id="mathematical-equations">Mathematical equations</h3>

<p>There are 7 mathematical equations to build a logistic regression model with a neural network mindset. Everything else is vectorization. So, the core concept in building neural networks is to understand these equations thoroughly.</p>

<p><em>Weighted Sum of \(i^{th}\) training example</em></p>
<div class="math-cover">
$$
z^{(i)} = w^Tx^{(i)} + b
$$
</div>

<p><em>Activation of \(i^{th}\) training example</em> (using sigmoid)</p>
<div class="math-cover">
$$
y'^{(i)} = a^{(i)} = \sigma(z^{(i)}) = \frac{1}{1+e^{-z^{(i)}}}
$$
</div>

<p><em>Loss function of \(i^{th}\) training example</em></p>
<div class="math-cover">
$$
L(a^{(i)},y^{(i)}) = -y^{(i)}log(a^{(i)}) - (1-y^{(i)})log(1-a^{(i)}))
$$
</div>

<p><em>Cost function for all training examples</em></p>
<div class="math-cover">
$$
J  = \frac{1}{m}\sum_{i=1}^m L(a^{(i)},y^{(i)}) \\
J  = -\frac{1}{m}\sum_{i=1}^m y^{(i)}log(a^{(i)}) + (1-y^{(i)})log(1-a^{(i)}))
$$
</div>

<p><em>Gradient Descent w.r.t cost function, weights and bias</em></p>
<div class="math-cover">
$$
\frac{dJ}{dw} = \frac{1}{m} X(A-Y)^T \\
\frac{dJ}{db} = \frac{1}{m} \sum_{i=1}^m (a^{(i)} - y^{(i)})
$$
</div>

<p><em>Parameters update rule</em></p>
<div class="math-cover">
$$
w = w - \alpha \frac{dJ}{dw} \\
b = b - \alpha \frac{dJ}{db}
$$
</div>

<h3 id="math-to-code">Math to Code</h3>

<p>We will be using the below functions to create and train our logistic regression neural network model.</p>

<h5 id="1-sigmoid">1. <span class="coding">sigmoid()</span></h5>
<ul>
  <li><em>Input</em>  - a number or a numpy array.</li>
  <li><em>Output</em> - sigmoid of the number or the numpy array.</li>
</ul>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2</pre></td><td class="code"><pre><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
	<span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">)))</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h5 id="2-init_params">2. <span class="coding">init_params()</span></h5>
<ul>
  <li><em>Input</em>  - dimension for weights (every value in an image’s vector has a weight associated with it).</li>
  <li><em>Output</em> - weight vector <span class="coding">w</span> and bias <span class="coding">b</span></li>
</ul>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4</pre></td><td class="code"><pre><span class="k">def</span> <span class="nf">init_params</span><span class="p">(</span><span class="n">dimension</span><span class="p">):</span>
	<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">dimension</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
	<span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>
	<span class="k">return</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h5 id="3-propagate">3. <span class="coding">propagate()</span></h5>
<ul>
  <li><em>Input</em>  - weight vector <span class="coding">w</span>, bias <span class="coding">b</span>, image matrix <span class="coding">X</span> and label vector <span class="coding">Y</span>.</li>
  <li><em>Output</em> - gradients <span class="coding">dw</span>, <span class="coding">db</span> and cost function <span class="coding">costs</span> for every 100 iterations.</li>
</ul>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18</pre></td><td class="code"><pre><span class="k">def</span> <span class="nf">propagate</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
	<span class="c"># num of training samples</span>
	<span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

	<span class="c"># forward pass</span>
	<span class="n">A</span>    <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
	<span class="n">cost</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">A</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">Y</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">A</span><span class="p">))))</span>

	<span class="c"># back propagation</span>
	<span class="n">dw</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="n">A</span><span class="o">-</span><span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
	<span class="n">db</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">A</span><span class="o">-</span><span class="n">Y</span><span class="p">))</span>

	<span class="n">cost</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

	<span class="c"># gradient dictionary</span>
	<span class="n">grads</span> <span class="o">=</span> <span class="p">{</span><span class="s">"dw"</span><span class="p">:</span> <span class="n">dw</span><span class="p">,</span> <span class="s">"db"</span><span class="p">:</span> <span class="n">db</span><span class="p">}</span>

	<span class="k">return</span> <span class="n">grads</span><span class="p">,</span> <span class="n">cost</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h5 id="4-optimize">4. <span class="coding">optimize()</span></h5>
<ul>
  <li><em>Input</em>  - weight vector <span class="coding">w</span>, bias <span class="coding">b</span>, image matrix <span class="coding">X</span>, label vector <span class="coding">Y</span>, number of iterations for gradient descent <span class="coding">epochs</span> and learning rate <span class="coding">lr</span>.</li>
  <li><em>Output</em> - parameter dictionary <span class="coding">params</span> holding updated <span class="coding">w</span> and <span class="coding">b</span>, gradient dictionary <span class="coding">grads</span> holding <span class="coding">dw</span> and <span class="coding">db</span>, and list of cost function <span class="coding">costs</span> after every 100 iterations.</li>
</ul>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25</pre></td><td class="code"><pre><span class="k">def</span> <span class="nf">optimize</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
	<span class="n">costs</span> <span class="o">=</span> <span class="p">[]</span>
	<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
		<span class="c"># calculate gradients</span>
		<span class="n">grads</span><span class="p">,</span> <span class="n">cost</span> <span class="o">=</span> <span class="n">propagate</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

		<span class="c"># get gradients</span>
		<span class="n">dw</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="s">"dw"</span><span class="p">]</span>
		<span class="n">db</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="s">"db"</span><span class="p">]</span>

		<span class="c"># update rule</span>
		<span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="p">(</span><span class="n">lr</span><span class="o">*</span><span class="n">dw</span><span class="p">)</span>
		<span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">-</span> <span class="p">(</span><span class="n">lr</span><span class="o">*</span><span class="n">db</span><span class="p">)</span>

		<span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
			<span class="n">costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
			<span class="k">print</span> <span class="p">(</span><span class="s">"cost after </span><span class="si">%</span><span class="s">i epochs: </span><span class="si">%</span><span class="s">f"</span> <span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cost</span><span class="p">))</span>

	<span class="c"># param dict</span>
	<span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s">"w"</span><span class="p">:</span> <span class="n">w</span><span class="p">,</span> <span class="s">"b"</span><span class="p">:</span> <span class="n">b</span><span class="p">}</span>

	<span class="c"># gradient dict</span>
	<span class="n">grads</span>  <span class="o">=</span> <span class="p">{</span><span class="s">"dw"</span><span class="p">:</span> <span class="n">dw</span><span class="p">,</span> <span class="s">"db"</span><span class="p">:</span> <span class="n">db</span><span class="p">}</span>

	<span class="k">return</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">costs</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h5 id="5-predict">5. <span class="coding">predict()</span></h5>
<ul>
  <li><em>Input</em>  - updated parameters <span class="coding">w</span>, <span class="coding">b</span> and image matrix <span class="coding">X</span>.</li>
  <li><em>Output</em> - predicted labels <span class="coding">Y_predict</span> for the image matrix <span class="coding">X</span>.</li>
</ul>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14</pre></td><td class="code"><pre><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
	<span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
	<span class="n">Y_predict</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">m</span><span class="p">))</span>
	<span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

	<span class="n">A</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

	<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
		<span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">:</span>
			<span class="n">Y_predict</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">Y_predict</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">i</span><span class="p">]</span>  <span class="o">=</span> <span class="mi">1</span>

	<span class="k">return</span> <span class="n">Y_predict</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h5 id="6-predict_image">6. <span class="coding">predict_image()</span></h5>
<ul>
  <li><em>Input</em>  - updated parameters <span class="coding">w</span>, <span class="coding">b</span> and a single image vector <span class="coding">X</span>.</li>
  <li><em>Output</em> - predicted label <span class="coding">Y_predict</span> for the single image vector <span class="coding">X</span>.</li>
</ul>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11</pre></td><td class="code"><pre><span class="k">def</span> <span class="nf">predict_image</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
	<span class="n">Y_predict</span> <span class="o">=</span> <span class="bp">None</span>
	<span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
	<span class="n">A</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
	<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
		<span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">:</span>
			<span class="n">Y_predict</span> <span class="o">=</span> <span class="mi">0</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">Y_predict</span> <span class="o">=</span> <span class="mi">1</span>

	<span class="k">return</span> <span class="n">Y_predict</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h3 id="fitting-it-all-together">Fitting it all together</h3>

<p>We will use all the above functions into a main function named <span class="coding">model()</span>.</p>
<ul>
  <li><em>Input</em> - Training image matrix <span class="coding">X_train</span>, Training image labels <span class="coding">Y_train</span>, Testing image matrix <span class="coding">X_test</span>, Test image labels <span class="coding">Y_test</span>, number of iterations for gradient descent <span class="coding">epochs</span> and learning rate <span class="coding">lr</span>.</li>
  <li><em>Output</em> - Logistic regression model dictionary having the parameters (w,b), predictions, costs, learning rate, epochs.</li>
</ul>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22</pre></td><td class="code"><pre><span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
	<span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
	<span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">costs</span> <span class="o">=</span> <span class="n">optimize</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>

	<span class="n">w</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s">"w"</span><span class="p">]</span>
	<span class="n">b</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s">"b"</span><span class="p">]</span>

	<span class="n">Y_predict_train</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X_train</span><span class="p">)</span>
	<span class="n">Y_predict_test</span>  <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>

	<span class="k">print</span> <span class="p">(</span><span class="s">"train_accuracy: {} </span><span class="si">%</span><span class="s">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">Y_predict_train</span> <span class="o">-</span> <span class="n">Y_train</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
	<span class="k">print</span> <span class="p">(</span><span class="s">"test_accuracy : {} </span><span class="si">%</span><span class="s">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">Y_predict_test</span>  <span class="o">-</span> <span class="n">Y_test</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>

	<span class="n">log_reg_model</span> <span class="o">=</span> <span class="p">{</span><span class="s">"costs"</span><span class="p">:</span> <span class="n">costs</span><span class="p">,</span>
				     <span class="s">"Y_predict_test"</span><span class="p">:</span> <span class="n">Y_predict_test</span><span class="p">,</span> 
					 <span class="s">"Y_predict_train"</span> <span class="p">:</span> <span class="n">Y_predict_train</span><span class="p">,</span> 
					 <span class="s">"w"</span> <span class="p">:</span> <span class="n">w</span><span class="p">,</span> 
					 <span class="s">"b"</span> <span class="p">:</span> <span class="n">b</span><span class="p">,</span>
					 <span class="s">"learning_rate"</span> <span class="p">:</span> <span class="n">lr</span><span class="p">,</span>
					 <span class="s">"epochs"</span><span class="p">:</span> <span class="n">epochs</span><span class="p">}</span>

	<span class="k">return</span> <span class="n">log_reg_model</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h3 id="training-the-model">Training the model</h3>

<p>Finally, we can train our model using the below code. This produces the train accuracy and test accuracy for the dataset.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2</pre></td><td class="code"><pre><span class="c"># activate the logistic regression model</span>
<span class="n">myModel</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
</pre></td></tr></tbody></table>
</div>
</div>

<div class="code-output highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28</pre></td><td class="code"><pre>Using TensorFlow backend.
train_labels : ['airplane', 'bike']
train_x shape: (12288, 1500)
train_y shape: (1, 1500)
test_x shape : (12288, 101)
test_y shape : (1, 101)
cost after 0 epochs: 0.693147
cost after 100 epochs: 0.136297
cost after 200 epochs: 0.092398
cost after 300 epochs: 0.076973
cost after 400 epochs: 0.067062
cost after 500 epochs: 0.059735
cost after 600 epochs: 0.053994
cost after 700 epochs: 0.049335
cost after 800 epochs: 0.045456
cost after 900 epochs: 0.042167
cost after 1000 epochs: 0.039335
cost after 1100 epochs: 0.036868
cost after 1200 epochs: 0.034697
cost after 1300 epochs: 0.032769
cost after 1400 epochs: 0.031045
cost after 1500 epochs: 0.029493
cost after 1600 epochs: 0.028088
cost after 1700 epochs: 0.026810
cost after 1800 epochs: 0.025642
cost after 1900 epochs: 0.024570
train_accuracy: 99.66666666666667 %
test_accuracy : 100.0 %
</pre></td></tr></tbody></table>
</div>
</div>

<h3 id="testing-the-trained-model">Testing the trained model (optional)</h3>

<p>We can use OpenCV to visualize our model’s performance on test dataset. Below code snipped takes it four images, our model predicts the label for these four images and displays it on the screen.</p>

<div class="code-head">train.py<span>code</span></div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26</pre></td><td class="code"><pre><span class="n">test_img_paths</span> <span class="o">=</span> <span class="p">[</span><span class="s">"G:</span><span class="se">\\</span><span class="s">workspace</span><span class="se">\\</span><span class="s">machine-intelligence</span><span class="se">\\</span><span class="s">deep-learning</span><span class="se">\\</span><span class="s">logistic-regression</span><span class="se">\\</span><span class="s">dataset</span><span class="se">\\</span><span class="s">test</span><span class="se">\\</span><span class="s">airplane</span><span class="se">\\</span><span class="s">image_0723.jpg"</span><span class="p">,</span>
                  <span class="s">"G:</span><span class="se">\\</span><span class="s">workspace</span><span class="se">\\</span><span class="s">machine-intelligence</span><span class="se">\\</span><span class="s">deep-learning</span><span class="se">\\</span><span class="s">logistic-regression</span><span class="se">\\</span><span class="s">dataset</span><span class="se">\\</span><span class="s">test</span><span class="se">\\</span><span class="s">airplane</span><span class="se">\\</span><span class="s">image_0713.jpg"</span><span class="p">,</span>
                  <span class="s">"G:</span><span class="se">\\</span><span class="s">workspace</span><span class="se">\\</span><span class="s">machine-intelligence</span><span class="se">\\</span><span class="s">deep-learning</span><span class="se">\\</span><span class="s">logistic-regression</span><span class="se">\\</span><span class="s">dataset</span><span class="se">\\</span><span class="s">test</span><span class="se">\\</span><span class="s">bike</span><span class="se">\\</span><span class="s">image_0782.jpg"</span><span class="p">,</span>
                  <span class="s">"G:</span><span class="se">\\</span><span class="s">workspace</span><span class="se">\\</span><span class="s">machine-intelligence</span><span class="se">\\</span><span class="s">deep-learning</span><span class="se">\\</span><span class="s">logistic-regression</span><span class="se">\\</span><span class="s">dataset</span><span class="se">\\</span><span class="s">test</span><span class="se">\\</span><span class="s">bike</span><span class="se">\\</span><span class="s">image_0799.jpg"</span><span class="p">,</span>
                  <span class="s">"G:</span><span class="se">\\</span><span class="s">workspace</span><span class="se">\\</span><span class="s">machine-intelligence</span><span class="se">\\</span><span class="s">deep-learning</span><span class="se">\\</span><span class="s">logistic-regression</span><span class="se">\\</span><span class="s">dataset</span><span class="se">\\</span><span class="s">test</span><span class="se">\\</span><span class="s">bike</span><span class="se">\\</span><span class="s">test_1.jpg"</span><span class="p">]</span>

<span class="k">for</span> <span class="n">test_img_path</span> <span class="ow">in</span> <span class="n">test_img_paths</span><span class="p">:</span>
	<span class="n">img_to_show</span>    <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">test_img_path</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
	<span class="n">img</span>            <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">test_img_path</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="n">image_size</span><span class="p">)</span>
	<span class="n">x</span>              <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
	<span class="n">x</span>              <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
	<span class="n">x</span>              <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
	<span class="n">predict</span>        <span class="o">=</span> <span class="n">predict_image</span><span class="p">(</span><span class="n">myModel</span><span class="p">[</span><span class="s">"w"</span><span class="p">],</span> <span class="n">myModel</span><span class="p">[</span><span class="s">"b"</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
	<span class="n">predict_label</span>  <span class="o">=</span> <span class="s">""</span>

	<span class="k">if</span> <span class="n">predict</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
		<span class="n">predict_label</span> <span class="o">=</span> <span class="s">"airplane"</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">predict_label</span> <span class="o">=</span> <span class="s">"bike"</span>

	<span class="c"># display the test image and the predicted label</span>
	<span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">img_to_show</span><span class="p">,</span> <span class="n">predict_label</span><span class="p">,</span> <span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">20</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">255</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
	<span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s">"test_image"</span><span class="p">,</span> <span class="n">img_to_show</span><span class="p">)</span>
	<span class="n">key</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xFF</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">key</span> <span class="o">==</span> <span class="mi">27</span><span class="p">):</span>
		<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre></td></tr></tbody></table>
</div>
</div>

<figure>
  <img src="/images/software/logistic-regression/out.gif" class="typical-image" />
  <figcaption>Figure 5. Making predictions using OpenCV on test data</figcaption>
</figure>

<h3 id="resources">Resources</h3>

<ol>
  <li><a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome" target="_blank">Coursera-Neural Networks and Deep Learning</a></li>
  <li><a href="https://www.youtube.com/watch?v=aircAruvnKk" target="_blank">But what is a Neural Network?</a></li>
  <li><a href="https://www.youtube.com/watch?v=IHZwWFHWa-w" target="_blank">Gradient Descent-How Neural Networks learn</a></li>
  <li><a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U" target="_blank">What is Backpropagation really doing?</a></li>
  <li><a href="https://www.youtube.com/watch?v=tIeHLnjs5U8" target="_blank">Backpropagation Calculus</a></li>
  <li><a href="https://keras.io/" target="_blank">Keras</a></li>
  <li><a href="http://www.numpy.org/" target="_blank">NumPy</a></li>
</ol>

				</div>
				<div class="note closers">
	<p>In case if you found something useful to add to this article or you found a bug in the code or would like to improve some points mentioned, feel free to write it down in the comments. Hope you found something useful here.</p>
	<p class="happy-learning">Happy learning!</p>
</div>
				
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

<hr>
<div class="share-it-box">
<p class="share-this">Share this post! </p>
<div id="share-box"> 
		<a href="whatsapp://send?text=http://localhost:4000/software/neural-nets-logistic-regression" data-action="share/whatsapp/share"><img src="/images/icons/whatsapp.png"/></a>

        <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/software/neural-nets-logistic-regression" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><img src="/images/icons/facebook.png"/></a>
       
        <a href="https://twitter.com/intent/tweet?text=Logistic Regression with a Neural Network mindset using NumPy and Python&url=http://localhost:4000/software/neural-nets-logistic-regression" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"><img src="/images/icons/twitter.png"/></a>

       <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/software/neural-nets-logistic-regression&title=Logistic Regression with a Neural Network mindset using NumPy and Python&summary=Build a binary classifier logistic regression model with a neural network mindset using numpy and python.&source=webjeda" onclick="window.open(this.href, 'mywin',
'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" ><img src="/images/icons/linkedin.png"/></a>                               
</div>
</div>
<hr>
			</article>
			
			<div class="show-comments" onclick="showComments()"><p id="show_comments"><span id="comment_count" class="disqus-comment-count" data-disqus-url="https://gogul09.github.io/software/neural-nets-logistic-regression"></span></p></div>

			<div id="disqus_thread"></div>
			<script>
				(function() {
					var d = document, s = d.createElement('script');
					s.src = '//gogul09.disqus.com/embed.js';
					s.setAttribute('data-timestamp', +new Date());
					(d.head || d.body).appendChild(s);
				})();
			</script>
			<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
		
		</div>
	</div>
</div>

<script type="text/javascript">
	
	window.onscroll = function() {
		sideBarScrollHandler();
		windowScrollHandler();
	};
	
	function sideBarScrollHandler() {
		if (document.body.scrollTop > 350 || document.documentElement.scrollTop > 350) {
			document.getElementById("sidebar_tracker").style.top = "20px";
		} else {
			document.getElementById("sidebar_tracker").style.top = "70px";
		}
	}
	
</script>
    </div>

    <div class="wrapper-footer">
      <footer class="footer">
        <p><span>&copy; 2019 - gogul ilango | opinions are my own</span></p>
       </footer>
     </div>
     
     <button onclick="topScroller()" id="btnScrollTop" title="Go to top" class="w3-animate-bottom"></button>

     <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
     <script src="https://apis.google.com/js/platform.js"></script>
     <script async defer src="https://buttons.github.io/buttons.js"></script>
     <script id="dsq-count-scr" src="//gogul09.disqus.com/count.js" async></script>
     <script src="/js/custom.js"></script>
     
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-93019594-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/software/neural-nets-logistic-regression',
		  'title': 'Logistic Regression with a Neural Network mindset using NumPy and Python'
		});
	</script>
	<!-- End Google Analytics -->


   </body>
   </html>
